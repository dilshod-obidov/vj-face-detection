{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get some random N samples from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_path = 'dataset/train/images'\n",
    "annotations_path = 'dataset/train/labels'\n",
    "sampled_images_path = 'sampled_data/images'\n",
    "sampled_annotations_path = 'sampled_data/labels'\n",
    "\n",
    "# Make directories for sampled data\n",
    "os.makedirs(sampled_images_path, exist_ok=True)\n",
    "os.makedirs(sampled_annotations_path, exist_ok=True)\n",
    "\n",
    "# List all images in the dataset\n",
    "all_images = [img for img in os.listdir(images_path) if img.endswith('.jpg')]\n",
    "\n",
    "# Randomly select 100 images\n",
    "sampled_images = random.sample(all_images, 100)\n",
    "\n",
    "# Copy sampled images and their corresponding annotation files\n",
    "for image_name in sampled_images:\n",
    "    # Copy image\n",
    "    src_image_path = os.path.join(images_path, image_name)\n",
    "    dst_image_path = os.path.join(sampled_images_path, image_name)\n",
    "    shutil.copy(src_image_path, dst_image_path)\n",
    "    \n",
    "    # Copy corresponding annotation\n",
    "    annotation_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "    src_annotation_path = os.path.join(annotations_path, annotation_name)\n",
    "    dst_annotation_path = os.path.join(sampled_annotations_path, annotation_name)\n",
    "    if os.path.exists(src_annotation_path):\n",
    "        shutil.copy(src_annotation_path, dst_annotation_path)\n",
    "\n",
    "print(\"Sampled 100 images and annotations.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop faces from dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = 'big_data/images/train'\n",
    "output_folder = 'data_cropped_faces/p'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the Haar Cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "i = 0\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):  # Add more extensions if needed\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20))\n",
    "\n",
    "        # Draw rectangles around detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            frame = image[y:y+h, x:x+w]\n",
    "            # save \n",
    "            cv2.imwrite(f'data_cropped_faces/p/face_{i}.jpg', frame)\n",
    "            i+=1\n",
    "\n",
    "        # Save the processed image to the output folder\n",
    "        # output_/path = os.path.join(output_folder, filename)\n",
    "        # cv2.imwrite(output_path, image)\n",
    "        \n",
    "        # Optional: Display the image (Press any key to close each image window)\n",
    "        # cv2.imshow('Detected Faces', image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Processing complete. Check the output folder for results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to your full dataset and target folder for negatives\n",
    "full_images_path = 'haarcascade-negatives/images'\n",
    "negatives_path = 'data/n'\n",
    "\n",
    "# Create directory for negatives if it doesn't exist\n",
    "os.makedirs(negatives_path, exist_ok=True)\n",
    "\n",
    "# List all images in the dataset\n",
    "all_images = [img for img in os.listdir(full_images_path) if img.endswith('.jpg')]\n",
    "\n",
    "# Randomly select 200 images\n",
    "negative_images = random.sample(all_images, 425)\n",
    "\n",
    "# Copy selected negative images to the negatives folder\n",
    "for image_name in negative_images:\n",
    "    src_image_path = os.path.join(full_images_path, image_name)\n",
    "    dst_image_path = os.path.join(negatives_path, image_name)\n",
    "    shutil.copy(src_image_path, dst_image_path)\n",
    "\n",
    "# Create the negatives.txt file\n",
    "# with open('negatives.txt', 'w') as f:\n",
    "#     for image_name in negative_images:\n",
    "#         f.write(os.path.join(negatives_path, image_name) + '\\n')\n",
    "\n",
    "print(\"Selected 425 negative images and created negatives.txt.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
